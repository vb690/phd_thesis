\section{Fully Connected Operation}
Given an input matrix $X$, an $N$ layers feedforward neural network can be defined as
\begin{gather}
    \label{fnn_operation}
    h_1 = \phi(\theta_1^\top X + \beta_1)\\ \nonumber
    h_2 = \phi(\theta_2^\top h_1  + \beta_2)\\ \nonumber
    \dots\\ \nonumber
    h_N = \phi(\theta_N^\top h_{N-1}  + \beta_N) \nonumber
\end{gather}
with $\phi$ being a non-linear function, ${\theta_1, \dots, \theta_N}$ a set of learnable weights and ${\beta_1, \dots, \beta_N}$ a set of learnable biases.

\section{Embedding Operation}
Given an input set of numerical indices $X = {1, 2, \dots, N}$, their embedding is defined as 
\begin{equation}
    h = \phi(\theta_{X,*})
\end{equation}
with $\phi$ being a non-linear function and $\theta$ an $N \times z$ learnable weights matrix.

\section{LSTM Cell Operation}
Given an input series $X_{t_1:T}$
\begin{equation}
    h = \phi(\theta_{X,*})
\end{equation}

